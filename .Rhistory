## Limpiamos
rm(list=ls())
##Llamamos las librerias necesarias
require(pacman)
p_load(tidyverse, caret, rio,
modelsummary,
gamlr,
class, skimr,dplyr, glmnet)
##Importamos data test y train
train_hogares <- readRDS("~/BD/Taller 2/dataPS2CSV/data/train_hogares.Rds")
test_hogares <- readRDS("~/BD/Taller 2/dataPS2CSV/data/test_hogares.Rds")
## summary db
skim(train_hogares) %>% head()
##Arreglamos algunos datos
train_hogares<-rename(train_hogares, numero_cuartos = P5000)
test_hogares<-rename(test_hogares, numero_cuartos = P5000)
train_hogares<-rename(train_hogares, numero_cuartos_usados = P5010)
test_hogares<-rename(test_hogares, numero_cuartos_usados = P5010)
train_hogares<-rename(train_hogares, vivienda_estado = P5090)
test_hogares<-rename(test_hogares, vivienda_estado = P5090)
train_hogares<-rename(train_hogares, pago_vivienda = P5100)
test_hogares<-rename(test_hogares, pago_vivienda = P5100)
train_hogares<-rename(train_hogares, estimadopagoarriendo = P5130)
test_hogares<-rename(test_hogares, estimadopagoarriendo = P5130)
train_hogares<-rename(train_hogares, pagoarriendo = P5140)
test_hogares<-rename(test_hogares, pagoarriendo = P5140)
#######Partimos la muestra train en 3 muestras########################
require(caret)
## First, split the training set off
set.seed(156)
split1 <- createDataPartition(train_hogares$Pobre, p = .7)[[1]]
length(split1)
head(split1, n=20)
other <- train_hogares[-split1,]
training <- train_hogares[ split1,]
## Now create the evaluation and test sets
set.seed(934)
split2 <- createDataPartition(other$Pobre, p = 1/3)[[1]]
evaluation <- other[ split2,]
testing <- other[-split2,]
dim(training)
dim(testing)
dim(evaluation)
########Lasso-logit######################################################
X<- model.matrix( ~ numero_cuartos + numero_cuartos_usados+factor(vivienda_estado)+ Nper +Npersug +Fex_dpto+Fex_c, training)
Y<- training$Pobre
##Encontramos el lambda por CV
set.seed(1011)
cv.model<- cv.glmnet(X, Y, alpha=1, family = "binomial")
cv.model
plot(cv.model)
##lambda mínimo
l.min <- cv.model$lambda.min
l.min
##lasso model con lambda mínimo
lasso.model <- glmnet(X,Y,
family = "binomial",
alpha=1,
lambda = l.min,
preProcess= c("center","scale"))
lasso.model$beta ##coeficientes de lasso-reg
#use fitted best model to make predictions
x.test <- model.matrix( ~ numero_cuartos + numero_cuartos_usados+factor(vivienda_estado)+ Nper +Npersug+Fex_dpto+Fex_c, testing)
lasso_predicted <- predict(lasso.model, newx =x.test, type="response")
lasso_predicted
predict_lasso <- ifelse(lasso_predicted > 0.5, 1, 0)
predict_lasso
# Model performance/accuracy
library(ROCR)
prediccion_lasso_testing<-data.frame(testing,predict_lasso)
prediccion_lasso_testing<-prediccion_lasso_testing %>% mutate(Pobre=factor(Pobre,levels=c(1,0),labels=c(1,0)))
prediccion_lasso_testing<-rename(prediccion_lasso_testing, lasso_prediccion =s0)
with(prediccion_lasso_testing,prop.table(table(Pobre,lasso_prediccion))) ##Un 16.9% son falsos negativos, es decir, el modelo no predice correctamente el 16.9% de los pobres
pred_lasso<-prediction(predict_lasso, prediccion_lasso_testing$Pobre)
roc_ROCR <- performance(pred_lasso,"tpr","fpr")
plot(roc_ROCR, main = "ROC curve", colorize = T)
abline(a = 0, b = 1)
auc_ROCR <- performance(pred_lasso, measure = "auc")
auc_ROCR@y.values[[1]] ##AUC=0,5714028
sensitivity(prediccion_lasso_testing$Pobre, prediccion_lasso_testing$s0)
confusionMatrix(as.factor(prediccion_lasso_testing$lasso_prediccion),as.factor(prediccion_lasso_testing$Pobre))
##Accuracy: 0.8098, Sensitivity: 0.168, Specificity: 0.97388
###RIDGE-REG###################################################################
ridge_model <- glmnet(
x           = X,
y           = Y,
alpha       = 0,
nlambda     = 100,
standardize = TRUE
)
set.seed(123)
ridge_error <- cv.glmnet(
x      = X,
y      = Y,
alpha  = 0,
nfolds = 10,
type.measure = "mse",
standardize  = TRUE
)
plot(ridge_error)
lambdamin_ridge<-ridge_error$lambda.min
lambdamin_ridge
# Mejor modelo lambda óptimo
ridge_model <- glmnet(
x           = X,
y           = Y,
alpha       = 0,
lambda      = lambdamin_ridge,
standardize = TRUE
)
# Coeficientes del modelo
ridge_coeficientes <- coef(ridge_model) %>%
as.matrix() %>%
as_tibble(rownames = "predictor") %>%
rename(coeficiente = s0)
ridge_coeficientes
##gráfica importancia coeficientes del modelo
ridge_coeficientes %>%
filter(predictor != "(Intercept)") %>%
ggplot(aes(x = predictor, y = coeficiente)) +
geom_col() +
labs(title = "Coeficientes del modelo Ridge") +
theme_bw() +
theme(axis.text.x = element_text(size = 6, angle = 45))
#use fitted best model to make predictions
x.test <- model.matrix( ~ numero_cuartos + numero_cuartos_usados+factor(vivienda_estado)+ Nper +Npersug+Fex_dpto+Fex_c, testing)
ridge_predicted <- predict(ridge_model, newx =x.test,type="response")
ridge_predicted
predict_ridge <- ifelse(ridge_predicted > 0.5, 1, 0)
predict_ridge
# Model performance/accuracy
library(ROCR)
prediccion_ridge_testing<-data.frame(testing,predict_ridge)
prediccion_ridge_testing<-prediccion_ridge_testing %>% mutate(Pobre=factor(Pobre,levels=c(1,0),labels=c(1,0)))
prediccion_ridge_testing<-rename(prediccion_ridge_testing, ridge_prediccion =s0)
with(prediccion_ridge_testing,prop.table(table(Pobre,ridge_prediccion))) ##Un 17.9% son falsos negativos, es decir, el modelo no predice correctamente el 16.9% de los pobres
pred_ridge<-prediction(predict_ridge, prediccion_ridge_testing$Pobre)
roc_ROCR_1 <- performance(pred_ridge,"tpr","fpr")
plot(roc_ROCR_1, main = "ROC curve", colorize = T)
abline(a = 0, b = 1)
auc_ROCR_ridge <- performance(pred_ridge, measure = "auc")
auc_ROCR_ridge@y.values[[1]] ##AUC=0,550705
confusionMatrix(as.factor(prediccion_ridge_testing$ridge_prediccion),as.factor(prediccion_ridge_testing$Pobre))
##Accuracy: 0.8074, Sensitivity: 0.1173, Specificity: 0.98409
###LOGIT-REG con lambda=0 ###################################################################
set.seed(1011)
##lasso model con lambda mínimo
logit.model <- glmnet(X,Y,
family = "binomial",
alpha=1,
lambda = 0,
preProcess=c("center","scale"))
logit.model$beta ##coeficientes de lasso-reg
#use fitted best model to make predictions
x.test <- model.matrix( ~ numero_cuartos + numero_cuartos_usados+factor(vivienda_estado)+ Nper +Npersug+Fex_dpto+Fex_c, testing)
logit_predicted <- predict(logit.model, newx =x.test,type="response")
logit_predicted
predict_logit <- ifelse(logit_predicted > 0.5, 1, 0)
predict_logit
# Model performance/accuracy
library(ROCR)
prediccion_logit_testing<-data.frame(testing,predict_logit)
prediccion_logit_testing<-prediccion_logit_testing %>% mutate(Pobre=factor(Pobre,levels=c(1,0),labels=c(1,0)))
prediccion_logit_testing<-rename(prediccion_logit_testing, logit_prediccion =s0)
with(prediccion_logit_testing,prop.table(table(Pobre,logit_prediccion))) ##Un 16.75% son falsos negativos, es decir, el modelo no predice correctamente el 16.9% de los pobres
pred_logit<-prediction(predict_logit, prediccion_logit_testing$Pobre)
roc_ROCR_logit <- performance(pred_logit,"tpr","fpr")
plot(roc_ROCR_logit, main = "ROC curve", colorize = T)
abline(a = 0, b = 1)
auc_ROCR_logit <- performance(pred_logit, measure = "auc")
auc_ROCR_logit@y.values[[1]] ##AUC=0.57475
confusionMatrix(as.factor(prediccion_logit_testing$logit_prediccion),as.factor(prediccion_logit_testing$Pobre))
##Accuracy: 0.8097, Sensitivity: 0.1781, Specificity: 0.97137
##HACEMOS REMUESTREO UPSAMPLING PARA CREAR NUEVOS MODELOS Lasso######################
training$Pobre <- factor(training$Pobre)
set.seed(1103)
upSampledTrain <- upSample(x = training,
y = training$Pobre,
## keep the class variable name the same:
yname = "Pobre")
dim(training)
dim(upSampledTrain)
table(upSampledTrain$Pobre)
X_up<- model.matrix( ~ numero_cuartos + numero_cuartos_usados+factor(vivienda_estado)+ Nper +Npersug +Fex_dpto+Fex_c, upSampledTrain)
Y_up<- upSampledTrain$Pobre
##Encontramos el lambda por CV
set.seed(1011)
cv.model_up<- cv.glmnet(X_up, Y_up, alpha=1, family = "binomial")
cv.model_up
plot(cv.model_up)
##lambda mínimo
l.min_up <- cv.model_up$lambda.min
l.min_up
##lasso model con lambda mínimo
lasso.model_up <- glmnet(X_up,Y_up,
family = "binomial",
alpha=1,
lambda = l.min_up,
preProcess= c("center","scale"))
lasso.model_up$beta ##coeficientes de lasso-reg
#use fitted best model to make predictions
x.test_up <- model.matrix( ~ numero_cuartos + numero_cuartos_usados+factor(vivienda_estado)+ Nper +Npersug+Fex_dpto+Fex_c, testing)
lasso_predictedup <- predict(lasso.model_up, newx =x.test_up, type="response")
lasso_predictedup
predict_lassoup <- ifelse(lasso_predictedup > 0.5, 1, 0)
predict_lassoup
# Model performance/accuracy
library(ROCR)
prediccion_lassoup_testing<-data.frame(testing,predict_lassoup)
prediccion_lassoup_testing<-prediccion_lassoup_testing %>% mutate(Pobre=factor(Pobre,levels=c(1,0),labels=c(1,0)))
prediccion_lassoup_testing<-rename(prediccion_lassoup_testing, lassoup_prediccion =s0)
with(prediccion_lassoup_testing,prop.table(table(Pobre,lassoup_prediccion))) ##Un 7.22% son falsos negativos, es decir, el modelo no predice correctamente el 16.9% de los pobres
pred_lassoup<-prediction(predict_lassoup, prediccion_lassoup_testing$Pobre)
roc_ROCRup <- performance(pred_lassoup,"tpr","fpr")
plot(roc_ROCRup, main = "ROC curve", colorize = T)
abline(a = 0, b = 1)
auc_ROCRup <- performance(pred_lassoup, measure = "auc")
auc_ROCRup@y.values[[1]] ##AUC=0,6892392
confusionMatrix(as.factor(prediccion_lassoup_testing$lassoup_prediccion),as.factor(prediccion_lassoup_testing$Pobre))
##Accuracy: 0.7152, Sensitivity: 0.6454, Specificity: 0.7331
##HACEMOS REMUESTREO UPSAMPLING PARA CREAR NUEVO MODELO RIDGE######################
##Encontramos el lambda por CV
set.seed(1013)
cv.model_ridgeup<- cv.glmnet(X_up, Y_up, alpha=0, family = "binomial")
cv.model_ridgeup
plot(cv.model_ridgeup)
##lambda mínimo
l.min_ridgeup <- cv.model_ridgeup$lambda.min
l.min_ridgeup
##ridge model con lambda mínimo
ridge.model_up <- glmnet(X_up,Y_up,
family = "binomial",
alpha=0,
lambda = l.min_ridgeup,
preProcess= c("center","scale"))
ridge.model_up$beta ##coeficientes de ridge-reg
#use fitted best model to make predictions
x.test_ridgeup <- model.matrix( ~ numero_cuartos + numero_cuartos_usados+factor(vivienda_estado)+ Nper +Npersug+Fex_dpto+Fex_c, testing)
ridge_predictedup <- predict(ridge.model_up, newx =x.test_ridgeup, type="response")
ridge_predictedup
predict_ridgeup <- ifelse(ridge_predictedup > 0.5, 1, 0)
predict_ridgeup
# Model performance/accuracy
library(ROCR)
prediccion_ridgeup_testing<-data.frame(testing,predict_ridgeup)
prediccion_ridgeup_testing<-prediccion_ridgeup_testing %>% mutate(Pobre=factor(Pobre,levels=c(1,0),labels=c(1,0)))
prediccion_ridgeup_testing<-rename(prediccion_ridgeup_testing, ridgeup_prediccion =s0)
with(prediccion_ridgeup_testing,prop.table(table(Pobre,ridgeup_prediccion))) ##Un 7.21% son falsos negativos, es decir, el modelo no predice correctamente el 16.9% de los pobres
pred_ridgeup<-prediction(predict_ridgeup, prediccion_ridgeup_testing$Pobre)
roc_ROCRridgeup <- performance(pred_ridgeup,"tpr","fpr")
plot(roc_ROCRridgeup, main = "ROC curve", colorize = T)
abline(a = 0, b = 1)
auc_ROCRridgeup <- performance(pred_ridgeup, measure = "auc")
auc_ROCRridgeup@y.values[[1]] ##AUC=0,68919
confusionMatrix(as.factor(prediccion_ridgeup_testing$ridgeup_prediccion),as.factor(prediccion_ridgeup_testing$Pobre))
##Accuracy: 0.7146, Sensitivity: 0.6462, Specificity: 0.7321
##HACEMOS REMUESTREO DOWNSAMPLING PARA CREAR NUEVOS MODELOS Lasso######################
set.seed(1107)
downSampledTrain <- downSample(x = training,
y = training$Pobre,
## keep the class variable name the same:
yname = "Pobre")
dim(training)
dim(downSampledTrain)
table(downSampledTrain$Pobre)
X_down<- model.matrix( ~ numero_cuartos + numero_cuartos_usados+factor(vivienda_estado)+ Nper +Npersug +Fex_dpto+Fex_c, downSampledTrain)
Y_down<- downSampledTrain$Pobre
##Encontramos el lambda por CV
set.seed(1001)
cv.model_down<- cv.glmnet(X_down, Y_down, alpha=1, family = "binomial")
cv.model_down
plot(cv.model_down)
##lambda mínimo
l.min_down <- cv.model_down$lambda.min
l.min_down
##lasso model con lambda mínimo
lasso.model_down <- glmnet(X_down,Y_down,
family = "binomial",
alpha=1,
lambda = l.min_down,
preProcess= c("center","scale"))
lasso.model_down$beta ##coeficientes de lasso-reg
#use fitted best model to make predictions
x.test_down <- model.matrix( ~ numero_cuartos + numero_cuartos_usados+factor(vivienda_estado)+ Nper +Npersug+Fex_dpto+Fex_c, testing)
lasso_predicteddown <- predict(lasso.model_down, newx =x.test_down, type="response")
lasso_predicteddown
predict_lassodown <- ifelse(lasso_predicteddown > 0.5, 1, 0)
predict_lassodown
# Model performance/accuracy
library(ROCR)
prediccion_lassodown_testing<-data.frame(testing,predict_lassodown)
prediccion_lassodown_testing<-prediccion_lassodown_testing %>% mutate(Pobre=factor(Pobre,levels=c(1,0),labels=c(1,0)))
prediccion_lassodown_testing<-rename(prediccion_lassodown_testing, lassodown_prediccion =s0)
with(prediccion_lassodown_testing,prop.table(table(Pobre,lassodown_prediccion))) ##Un 7.27% son falsos negativos, es decir, el modelo no predice correctamente el 16.9% de los pobres
pred_lassodown<-prediction(predict_lassodown, prediccion_lassodown_testing$Pobre)
roc_ROCRdown <- performance(pred_lassodown,"tpr","fpr")
plot(roc_ROCRdown, main = "ROC curve", colorize = T)
abline(a = 0, b = 1)
auc_ROCRdown <- performance(pred_lassodown, measure = "auc")
auc_ROCRdown@y.values[[1]] ##AUC=0,689228
confusionMatrix(as.factor(prediccion_lassodown_testing$lassodown_prediccion),as.factor(prediccion_lassodown_testing$Pobre))
##Accuracy: 0.7165, Sensitivity: 0.6431, Specificity: 0.7353
##HACEMOS REMUESTREO DOWNSAMPLING PARA CREAR NUEVO MODELO RIDGE######################
##Encontramos el lambda por CV
set.seed(1113)
cv.model_ridgedown<- cv.glmnet(X_down, Y_down, alpha=0, family = "binomial")
cv.model_ridgedown
plot(cv.model_ridgedown)
##lambda mínimo
l.min_ridgedown <- cv.model_ridgedown$lambda.min
l.min_ridgedown
##ridge model con lambda mínimo
ridge.model_down <- glmnet(X_down,Y_down,
family = "binomial",
alpha=0,
lambda = l.min_ridgedown,
preProcess= c("center","scale"))
ridge.model_down$beta ##coeficientes de ridge-reg
#use fitted best model to make predictions
x.test_ridgedown <- model.matrix( ~ numero_cuartos + numero_cuartos_usados+factor(vivienda_estado)+ Nper +Npersug+Fex_dpto+Fex_c, testing)
ridge_predicteddown <- predict(ridge.model_down, newx =x.test_ridgedown, type="response")
ridge_predicteddown
predict_ridgedown <- ifelse(ridge_predicteddown > 0.5, 1, 0)
predict_ridgedown
# Model performance/accuracy
library(ROCR)
prediccion_ridgedown_testing<-data.frame(testing,predict_ridgedown)
prediccion_ridgedown_testing<-prediccion_ridgedown_testing %>% mutate(Pobre=factor(Pobre,levels=c(1,0),labels=c(1,0)))
prediccion_ridgedown_testing<-rename(prediccion_ridgedown_testing, ridgedown_prediccion =s0)
with(prediccion_ridgedown_testing,prop.table(table(Pobre,ridgedown_prediccion))) ##Un 7.25% son falsos negativos, es decir, el modelo no predice correctamente el 16.9% de los pobres
pred_ridgedown<-prediction(predict_ridgedown, prediccion_ridgedown_testing$Pobre)
roc_ROCRridgedown <- performance(pred_ridgedown,"tpr","fpr")
plot(roc_ROCRridgedown, main = "ROC curve", colorize = T)
abline(a = 0, b = 1)
auc_ROCRridgedown <- performance(pred_ridgedown, measure = "auc")
auc_ROCRridgedown@y.values[[1]] ##AUC=0,6888
confusionMatrix(as.factor(prediccion_ridgedown_testing$ridgedown_prediccion),as.factor(prediccion_ridgedown_testing$Pobre))
##Accuracy: 0.7154, Sensitivity: 0.6440, Specificity: 0.7337
##RESUMEN MODELOS REALIZADOS Y SUS INDICADORES###
##Mod 1 Lasso-Logit##
with(prediccion_lasso_testing,prop.table(table(Pobre,lasso_prediccion))) ##Un 16.9% son falsos negativos, es decir, el modelo no predice correctamente el 16.9% de los pobres
auc_ROCR@y.values[[1]] ##AUC=0,5714028
sensitivity(prediccion_lasso_testing$Pobre, prediccion_lasso_testing$s0)
confusionMatrix(as.factor(prediccion_lasso_testing$lasso_prediccion),as.factor(prediccion_lasso_testing$Pobre))
##Accuracy: 0.8098, Sensitivity: 0.168, Specificity: 0.97388
##Mod 2 Ridge-Logit##
with(prediccion_ridge_testing,prop.table(table(Pobre,ridge_prediccion))) ##Un 17.9% son falsos negativos, es decir, el modelo no predice correctamente el 16.9% de los pobres
auc_ROCR_ridge <- performance(pred_ridge, measure = "auc")
auc_ROCR_ridge@y.values[[1]] ##AUC=0,550705
confusionMatrix(as.factor(prediccion_ridge_testing$ridge_prediccion),as.factor(prediccion_ridge_testing$Pobre))
##Accuracy: 0.8074, Sensitivity: 0.1173, Specificity: 0.98409
##Mod 3 LOGIT-REG con lambda=0#########
with(prediccion_logit_testing,prop.table(table(Pobre,logit_prediccion))) ##Un 16.75% son falsos negativos, es decir, el modelo no predice correctamente el 16.9% de los pobres
auc_ROCR_logit <- performance(pred_logit, measure = "auc")
auc_ROCR_logit@y.values[[1]] ##AUC=0.57475
confusionMatrix(as.factor(prediccion_logit_testing$logit_prediccion),as.factor(prediccion_logit_testing$Pobre))
##Accuracy: 0.8097, Sensitivity: 0.1781, Specificity: 0.97137
##Mod 4 Upsampling Lasso######
with(prediccion_lassoup_testing,prop.table(table(Pobre,lassoup_prediccion))) ##Un 7.22% son falsos negativos, es decir, el modelo no predice correctamente el 16.9% de los pobres
auc_ROCRup <- performance(pred_lassoup, measure = "auc")
auc_ROCRup@y.values[[1]] ##AUC=0,6892392
confusionMatrix(as.factor(prediccion_lassoup_testing$lassoup_prediccion),as.factor(prediccion_lassoup_testing$Pobre))
##Accuracy: 0.7152, Sensitivity: 0.6454, Specificity: 0.7331
##Mod 5 Upsampling Ridge######
with(prediccion_ridgeup_testing,prop.table(table(Pobre,ridgeup_prediccion))) ##Un 7.21% son falsos negativos, es decir, el modelo no predice correctamente el 16.9% de los pobres
auc_ROCRridgeup <- performance(pred_ridgeup, measure = "auc")
auc_ROCRridgeup@y.values[[1]] ##AUC=0,68919
confusionMatrix(as.factor(prediccion_ridgeup_testing$ridgeup_prediccion),as.factor(prediccion_ridgeup_testing$Pobre))
##Accuracy: 0.7146, Sensitivity: 0.6462, Specificity: 0.7321
##Mod 6 Lasso downsampling###
with(prediccion_lassodown_testing,prop.table(table(Pobre,lassodown_prediccion))) ##Un 7.27% son falsos negativos, es decir, el modelo no predice correctamente el 16.9% de los pobres
auc_ROCRdown <- performance(pred_lassodown, measure = "auc")
auc_ROCRdown@y.values[[1]] ##AUC=0,689228
confusionMatrix(as.factor(prediccion_lassodown_testing$lassodown_prediccion),as.factor(prediccion_lassodown_testing$Pobre))
##Accuracy: 0.7165, Sensitivity: 0.6431, Specificity: 0.7353
## Mod 7 Ridge downsampling####
with(prediccion_ridgedown_testing,prop.table(table(Pobre,ridgedown_prediccion))) ##Un 7.25% son falsos negativos, es decir, el modelo no predice correctamente el 16.9% de los pobres
auc_ROCRridgedown <- performance(pred_ridgedown, measure = "auc")
auc_ROCRridgedown@y.values[[1]] ##AUC=0,6888
confusionMatrix(as.factor(prediccion_ridgedown_testing$ridgedown_prediccion),as.factor(prediccion_ridgedown_testing$Pobre))
##Accuracy: 0.7154, Sensitivity: 0.6440, Specificity: 0.7337
##Mod 5 Upsampling Ridge######
with(prediccion_ridgeup_testing,prop.table(table(Pobre,ridgeup_prediccion))) ##Un 7.21% son falsos negativos, es decir, el modelo no predice correctamente el 16.9% de los pobres
auc_ROCRridgeup <- performance(pred_ridgeup, measure = "auc")
auc_ROCRridgeup@y.values[[1]] ##AUC=0,68919
confusionMatrix(as.factor(prediccion_ridgeup_testing$ridgeup_prediccion),as.factor(prediccion_ridgeup_testing$Pobre))
##Accuracy: 0.7146, Sensitivity: 0.6462, Specificity: 0.7321
##Mejor Modelo##
##De acuerdo con los AUC encontrados, el mejor modelo es el Mod 5 Upsampling Ridge
##ya que tiene la menor tasa de falsos positivos (7,21%), su sensibilidad es la mayor(64,62%)
## y su AUC también es el mayor (0,6892)
##Con este modelo Predecimos ahora si el testing_hogares##
#use fitted best model to make predictions
x.test_final <- model.matrix( ~ numero_cuartos + numero_cuartos_usados+factor(vivienda_estado)+ Nper +Npersug+Fex_dpto+Fex_c, test_hogares)
ridge_predictedfinal <- predict(ridge.model_up, newx =x.test_final, type="response")
ridge_predictedfinal
predict_ridgefinal <- ifelse(ridge_predictedfinal > 0.5, 1, 0)
predict_ridgefinal
library(ROCR)
prediccion_ridgefinal_testing<-data.frame(test_hogares,predict_ridgefinal)
prediccion_ridgefinal_testing<-rename(prediccion_ridgefinal_testing, ridgefinal_prediccion =s0)
##Prediccion pobreza mejor modelo con su correspondiente ID
prediccion_mejor_mod<-data.frame(prediccion_ridgefinal_testing$id,prediccion_ridgefinal_testing$ridgefinal_prediccion)
prediccion_mejor_mod<-rename(prediccion_mejor_mod, Prediccion_final_pobre =prediccion_ridgefinal_testing.ridgefinal_prediccion)
prediccion_mejor_mod<-rename(prediccion_mejor_mod, Hogar =prediccion_ridgefinal_testing.id)
View(prediccion_mejor_mod)
View(prediccion_mejor_mod)
write.csv(prediccion_mejor_mod,"C:/Users/francisco.alejandro1/Documents/BD/Problem Set 2/Problem-Set-2/document/resultados_clasificacion.csv", row.names = FALSE)
